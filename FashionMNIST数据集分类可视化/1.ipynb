{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b909cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "lr = 0.15\n",
    "gamma = 0\n",
    "epochs = 10\n",
    "bs = 128\n",
    "\n",
    "mnist = torchvision.datasets.FashionMNIST(\n",
    "    root = \"./data\"\n",
    "    , train=True # 使用训练数据集\n",
    "    , download=True \n",
    "    , transform=transforms.ToTensor() # 将数据转换为Tensor\n",
    "    )\n",
    "\n",
    "batchdata = DataLoader(mnist, batch_size=bs, shuffle=True)\n",
    "\n",
    "input_ = mnist.data[0].numel() # 查看一个样本共有多少个特征\n",
    "output_ = len(mnist.targets.unique())\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features=3, out_features=10):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, 128, bias=False)\n",
    "        self.output = nn.Linear(128, out_features, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        z_hat = self.output(sigma1)\n",
    "        # log_sigma2 = torch.log_softmax(z_hat, dim=1)\n",
    "        return z_hat\n",
    "    \n",
    "\n",
    "def fit(net, batchdata, lr=0.01, gamma=0.9, epochs=5):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=gamma)\n",
    "    correct = 0 \n",
    "    samples = 0\n",
    "\n",
    "    for i_epoch in range(epochs):\n",
    "        for i_batch, (xb, yb) in enumerate(batchdata):\n",
    "            yb = yb.view(xb.shape[0])\n",
    "            opt.zero_grad() # 清空梯度\n",
    "            z_hat = net.forward(xb)\n",
    "            loss = criterion(z_hat, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # 计算准确率\n",
    "            y_hat = torch.max(z_hat, dim=1)[1] \n",
    "            # softmax/logsoftmax函数对z_hat是单调递增的，因此对比z_hat的值也可以获得y_hat \n",
    "            correct += torch.sum(y_hat==yb)\n",
    "            samples += xb.shape[0]\n",
    "\n",
    "            if (i_batch+1) % 125 == 0 or i_batch == len(batchdata)-1:\n",
    "                print(\"Epoch{}: [{}/{}({:.0f}%)] \\t Loss: {:.6f} \\t Accuracy:{:.3f}\".format(\n",
    "                       i_epoch+1\n",
    "                       , samples\n",
    "                       , len(batchdata.dataset)*epochs\n",
    "                       , 100*samples/(len(batchdata.dataset)*epochs)\n",
    "                       , loss.data.item()\n",
    "                       , float(100*correct/samples)\n",
    "                       )\n",
    "                      )\n",
    "\n",
    "torch.manual_seed(531)\n",
    "net = Model(input_, output_)\n",
    "fit(net, batchdata, lr=lr, gamma=gamma, epochs=epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
